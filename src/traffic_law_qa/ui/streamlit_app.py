"""
Advanced Streamlit web interface for Vietnamese Traffic Law Q&A system.
Integrates Knowledge Graph and Semantic Reasoning capabilities.
"""

import streamlit as st
import json
import time
import sys
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
import plotly.express as px
import plotly.graph_objects as go
import pandas as pd
from datetime import datetime

# Add src to path for imports
src_path = Path(__file__).parent.parent.parent
sys.path.insert(0, str(src_path))

# Also try adding the project root
project_root = Path(__file__).parent.parent.parent.parent / "src"
sys.path.insert(0, str(project_root))

from traffic_law_qa.knowledge.qa_system import TrafficLawQASystem
from traffic_law_qa.knowledge.knowledge_graph import NodeType

# Page configuration
st.set_page_config(
    page_title="Há»‡ thá»‘ng Q&A Luáº­t Giao thÃ´ng Viá»‡t Nam - Tri thá»©c Ngá»¯ nghÄ©a",
    page_icon="ðŸš¦",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Configure logging
logging.basicConfig(level=logging.INFO)

# Constants
VIOLATIONS_DATA_PATH = Path(__file__).parent.parent.parent.parent / "data" / "processed" / "violations.json"

@st.cache_resource
def load_qa_system():
    """Load and cache the QA system."""
    try:
        return TrafficLawQASystem(str(VIOLATIONS_DATA_PATH))
    except Exception as e:
        st.error(f"KhÃ´ng thá»ƒ khá»Ÿi táº¡o há»‡ thá»‘ng: {e}")
        return None


def main():
    """Main Streamlit application with knowledge graph integration."""
    
    # Header
    st.title("ðŸš¦ Há»‡ thá»‘ng Q&A Luáº­t Giao thÃ´ng Viá»‡t Nam")
    st.markdown("*Há»‡ thá»‘ng Tri thá»©c Ngá»¯ nghÄ©a vá»›i Äá»“ thá»‹ Tri thá»©c vÃ  Suy luáº­n Semantic*")
    
    # Load QA system
    qa_system = load_qa_system()
    if not qa_system:
        st.error("KhÃ´ng thá»ƒ khá»Ÿi Ä‘á»™ng há»‡ thá»‘ng. Vui lÃ²ng kiá»ƒm tra dá»¯ liá»‡u.")
        return
    
    # Sidebar
    with st.sidebar:
        st.header("ðŸŽ›ï¸ CÃ i Ä‘áº·t há»‡ thá»‘ng")
        
        # Search parameters
        st.subheader("ðŸ” Tham sá»‘ tÃ¬m kiáº¿m")
        max_results = st.slider(
            "Sá»‘ káº¿t quáº£ tá»‘i Ä‘a",
            min_value=1,
            max_value=20,
            value=5,
            help="Sá»‘ lÆ°á»£ng káº¿t quáº£ tá»‘i Ä‘a hiá»ƒn thá»‹"
        )
        
        similarity_threshold = st.slider(
            "NgÆ°á»¡ng tÆ°Æ¡ng Ä‘á»“ng ngá»¯ nghÄ©a",
            min_value=0.3,
            max_value=0.9,
            value=0.6,
            step=0.05,
            help="NgÆ°á»¡ng tá»‘i thiá»ƒu cho Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng (0.6 = khuyáº¿n nghá»‹)"
        )
        
        st.markdown("---")
        
        # System information
        st.subheader("ðŸ“Š ThÃ´ng tin há»‡ thá»‘ng")
        if st.button("Xem thá»‘ng kÃª chi tiáº¿t"):
            display_system_dashboard(qa_system)
            
        # Display basic stats
        stats = qa_system.get_system_statistics()
        st.metric("Tá»•ng sá»‘ vi pháº¡m", stats['knowledge_graph']['node_types'].get('behavior', 0))
        st.metric("Nodes trong Knowledge Graph", stats['knowledge_graph']['total_nodes'])
        st.metric("Relations", stats['knowledge_graph']['total_relations'])
        
        st.markdown("---")
        
        # Advanced features
        st.subheader("ðŸš€ TÃ­nh nÄƒng nÃ¢ng cao")
        if st.button("ðŸ§  KhÃ¡m phÃ¡ Knowledge Graph"):
            st.session_state.show_kg_explorer = True
            
        if st.button("ðŸ”¬ Benchmark há»‡ thá»‘ng"):
            st.session_state.show_benchmark = True
    
    # Navigation tabs
    tab1, tab2, tab3, tab4 = st.tabs([
        "ðŸ” TÃ¬m kiáº¿m thÃ´ng minh", 
        "ðŸ§  KhÃ¡m phÃ¡ tri thá»©c", 
        "ðŸ“Š PhÃ¢n tÃ­ch há»‡ thá»‘ng",
        "ðŸ”¬ ÄÃ¡nh giÃ¡ hiá»‡u suáº¥t"
    ])
    
    with tab1:
        display_smart_search_interface(qa_system, max_results, similarity_threshold)
        
    with tab2:
        display_knowledge_explorer(qa_system)
        
    with tab3:
        display_system_dashboard(qa_system)
        
    with tab4:
        display_benchmark_interface(qa_system)


def display_smart_search_interface(qa_system: TrafficLawQASystem, max_results: int, similarity_threshold: float):
    """Display the main search interface with advanced features."""
    
    st.header("ðŸ” TÃ¬m kiáº¿m thÃ´ng minh vá»›i Suy luáº­n Ngá»¯ nghÄ©a")
    
    # Example queries
    col1, col2 = st.columns([3, 1])
    
    with col2:
        st.subheader("ðŸ’¡ VÃ­ dá»¥ máº«u")
        example_queries = [
            "Äi xe mÃ¡y vÆ°á»£t Ä‘Ã¨n Ä‘á»",
            "KhÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm khi lÃ¡i xe mÃ¡y", 
            "LÃ¡i xe Ã´ tÃ´ quÃ¡ tá»‘c Ä‘á»™ 20km/h",
            "Äá»— xe trÃªn vá»‰a hÃ¨",
            "Uá»‘ng rÆ°á»£u bia rá»“i lÃ¡i xe vá»›i ná»“ng Ä‘á»™ 0.3mg/l",
            "KhÃ´ng cÃ³ báº±ng lÃ¡i xe",
            "Chá»Ÿ quÃ¡ sá»‘ ngÆ°á»i quy Ä‘á»‹nh",
            "VÆ°á»£t Ä‘Ã¨n vÃ ng táº¡i ngÃ£ tÆ°"
        ]
        
        for i, example in enumerate(example_queries):
            if st.button(f"ðŸ“ {example}", key=f"example_{i}"):
                st.session_state.selected_query = example
    
    with col1:
        # Search input
        query = st.text_area(
            "Nháº­p cÃ¢u há»i vá» luáº­t giao thÃ´ng (tiáº¿ng Viá»‡t tá»± nhiÃªn):",
            value=st.session_state.get('selected_query', ''),
            placeholder="VÃ­ dá»¥: TÃ´i Ä‘i xe mÃ¡y khÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm, vÆ°á»£t Ä‘Ã¨n Ä‘á» thÃ¬ bá»‹ pháº¡t bao nhiÃªu tiá»n?",
            height=120,
            help="Há»‡ thá»‘ng hiá»ƒu tiáº¿ng Viá»‡t tá»± nhiÃªn. Báº¡n cÃ³ thá»ƒ há»i nhÆ° nÃ³i chuyá»‡n bÃ¬nh thÆ°á»ng."
        )
        
        # Search controls
        col_search, col_clear = st.columns([2, 1])
        
        with col_search:
            search_button = st.button("ðŸ” TÃ¬m kiáº¿m vá»›i AI", type="primary", width="stretch")
            
        with col_clear:
            if st.button("ðŸ—‘ï¸ XÃ³a", width="stretch"):
                st.session_state.selected_query = ""
                st.rerun()
        
        # Search results
        if search_button and query.strip():
            with st.spinner("ðŸ§  Há»‡ thá»‘ng Ä‘ang phÃ¢n tÃ­ch cÃ¢u há»i vÃ  suy luáº­n..."):
                start_time = time.time()
                
                try:
                    results = qa_system.ask_question(
                        query, 
                        max_results=max_results,
                        similarity_threshold=similarity_threshold
                    )
                    
                    search_time = time.time() - start_time
                    display_intelligent_results(results, search_time)
                    
                except Exception as e:
                    st.error(f"Lá»—i khi xá»­ lÃ½ cÃ¢u há»i: {str(e)}")


def display_intelligent_results(results: Dict[str, Any], search_time: float):
    """Display results with intelligent analysis and reasoning."""
    
    st.markdown("---")
    st.header("ðŸ“‹ Káº¿t quáº£ phÃ¢n tÃ­ch")
    
    # Performance metrics
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("â±ï¸ Thá»i gian", f"{search_time:.2f}s")
    with col2:
        confidence = results.get('confidence', 'none')
        confidence_color = {'high': 'ðŸŸ¢', 'medium': 'ðŸŸ¡', 'low': 'ðŸŸ ', 'none': 'ðŸ”´', 'error': 'âŒ'}
        st.metric("ðŸŽ¯ Äá»™ tin cáº­y", f"{confidence_color.get(confidence, 'â“')} {confidence}")
    with col3:
        similarity = results.get('similarity_score', 0)
        st.metric("ðŸ”— Äá»™ tÆ°Æ¡ng Ä‘á»“ng", f"{similarity:.2f}")
    with col4:
        intent_type = results.get('intent', {}).get('type', 'unknown')
        st.metric("ðŸŽ­ Intent", intent_type.replace('_', ' ').title())
    
    # Main answer
    if results.get('confidence') in ['high', 'medium']:
        st.success("âœ… **TÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p**")
        
        # Display answer with formatting
        answer = results.get('answer', '')
        st.markdown(f"### ðŸ’¬ Tráº£ lá»i:\n{answer}")
        
        # Similar cases
        similar_cases = results.get('similar_cases', [])
        if similar_cases:
            st.markdown("### ðŸ”„ CÃ¡c trÆ°á»ng há»£p tÆ°Æ¡ng tá»±:")
            for i, case in enumerate(similar_cases[:3]):
                with st.expander(f"TrÆ°á»ng há»£p {i+1} - Äá»™ tÆ°Æ¡ng Ä‘á»“ng: {case['similarity']:.2f}"):
                    st.write(f"**MÃ´ táº£:** {case['description']}")
                    st.write(f"**PhÃ¢n loáº¡i:** {case.get('category', 'N/A')}")
        
        # Citations and legal references
        citations = results.get('citations', [])
        if citations:
            st.markdown("### ðŸ“š TrÃ­ch dáº«n phÃ¡p lÃ½:")
            for citation in citations:
                st.info(f"ðŸ“‹ **{citation['source']}** ({citation.get('type', 'legal_document')})")
                
    elif results.get('confidence') == 'none':
        st.warning("âš ï¸ **KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin phÃ¹ há»£p**")
        st.markdown(results.get('answer', 'KhÃ´ng cÃ³ dá»¯ liá»‡u phÃ¹ há»£p.'))
        
        suggestions = results.get('additional_info', {}).get('suggestions', [])
        if suggestions:
            st.markdown("### ðŸ’¡ Gá»£i Ã½:")
            for suggestion in suggestions:
                st.write(f"â€¢ {suggestion}")
    else:
        st.error("âŒ **ÄÃ£ xáº£y ra lá»—i**")
        st.write(results.get('answer', 'Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh.'))
    
    # Advanced information
    with st.expander("ðŸ”§ ThÃ´ng tin ká»¹ thuáº­t (dÃ nh cho nhÃ  phÃ¡t triá»ƒn)"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.json({
                'intent_analysis': results.get('intent', {}),
                'processing_metrics': {
                    'search_time': f"{search_time:.3f}s",
                    'total_results_found': results.get('additional_info', {}).get('total_results_found', 0),
                    'similarity_threshold_used': 0.6
                }
            })
            
        with col2:
            matched_entities = results.get('additional_info', {}).get('matched_entities', [])
            if matched_entities:
                st.write("**Entities Ä‘Æ°á»£c trÃ­ch xuáº¥t:**")
                for entity in matched_entities:
                    st.write(f"â€¢ {entity.get('text', 'N/A')} ({entity.get('type', 'N/A')})")


def display_knowledge_explorer(qa_system: TrafficLawQASystem):
    """Display knowledge graph exploration interface."""
    
    st.header("ðŸ§  KhÃ¡m phÃ¡ Äá»“ thá»‹ Tri thá»©c")
    st.markdown("*KhÃ¡m phÃ¡ má»‘i quan há»‡ giá»¯a HÃ nh vi â†’ Má»©c pháº¡t â†’ Äiá»u luáº­t â†’ Biá»‡n phÃ¡p bá»• sung*")
    
    # Node type statistics
    stats = qa_system.get_system_statistics()
    kg_stats = stats['knowledge_graph']
    
    st.subheader("ðŸ“Š Thá»‘ng kÃª Nodes theo loáº¡i")
    
    # Create visualization
    node_types = kg_stats['node_types']
    if node_types:
        col1, col2 = st.columns([1, 1])
        
        with col1:
            # Pie chart
            fig_pie = px.pie(
                values=list(node_types.values()),
                names=list(node_types.keys()),
                title="PhÃ¢n bá»‘ Node Types"
            )
            st.plotly_chart(fig_pie, width="stretch")
            
        with col2:
            # Bar chart
            fig_bar = px.bar(
                x=list(node_types.keys()),
                y=list(node_types.values()),
                title="Sá»‘ lÆ°á»£ng Nodes theo loáº¡i"
            )
            st.plotly_chart(fig_bar, width="stretch")
    
    # Relationship statistics
    st.subheader("ðŸ”— Thá»‘ng kÃª Relations")
    relation_types = kg_stats.get('relation_types', {})
    if relation_types:
        df_relations = pd.DataFrame([
            {'Loáº¡i quan há»‡': k.replace('_', ' ').title(), 'Sá»‘ lÆ°á»£ng': v}
            for k, v in relation_types.items()
        ])
        st.dataframe(df_relations, width="stretch")
    
    # Sample exploration
    st.subheader("ðŸ” KhÃ¡m phÃ¡ máº«u")
    
    behavior_nodes = qa_system.knowledge_graph.find_nodes_by_type(NodeType.BEHAVIOR)
    if behavior_nodes:
        selected_behavior = st.selectbox(
            "Chá»n má»™t hÃ nh vi Ä‘á»ƒ khÃ¡m phÃ¡:",
            options=[(node.id, node.label) for node in behavior_nodes[:20]],
            format_func=lambda x: x[1]
        )
        
        if selected_behavior:
            behavior_id = selected_behavior[0]
            chain = qa_system.knowledge_graph.get_behavior_penalty_chain(behavior_id)
            
            st.markdown(f"### ðŸ”„ Chuá»—i tri thá»©c cho: *{selected_behavior[1]}*")
            
            # Display chain
            if chain:
                # Behavior
                behavior = chain.get('behavior')
                if behavior:
                    st.markdown(f"**ðŸŽ­ HÃ nh vi:** {behavior.label}")
                    if behavior.properties.get('category'):
                        st.markdown(f"**ðŸ“‚ Danh má»¥c:** {behavior.properties['category']}")
                
                # Penalties
                penalties = chain.get('penalties', [])
                if penalties:
                    st.markdown("**ðŸ’° Má»©c pháº¡t:**")
                    for penalty in penalties:
                        fine_min = penalty.properties.get('fine_min', 0)
                        fine_max = penalty.properties.get('fine_max', 0)
                        if fine_min and fine_max:
                            st.write(f"â€¢ {fine_min:,} - {fine_max:,} VNÄ")
                        else:
                            st.write(f"â€¢ {penalty.label}")
                
                # Law articles
                law_articles = chain.get('law_articles', [])
                if law_articles:
                    st.markdown("**âš–ï¸ CÄƒn cá»© phÃ¡p lÃ½:**")
                    for law in law_articles:
                        st.write(f"â€¢ {law.label}")
                
                # Additional measures
                additional_measures = chain.get('additional_measures', [])
                if additional_measures:
                    st.markdown("**ðŸ”§ Biá»‡n phÃ¡p bá»• sung:**")
                    for measure in additional_measures:
                        st.write(f"â€¢ {measure.label}")
            
            # Similar behaviors
            st.markdown("### ðŸ”„ HÃ nh vi tÆ°Æ¡ng tá»±")
            similar_behaviors = qa_system.reasoning_engine.get_similar_behaviors(behavior_id, limit=5)
            
            if similar_behaviors:
                for similar_node, similarity in similar_behaviors:
                    st.write(f"â€¢ **{similar_node.label}** (Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng: {similarity:.3f})")
            else:
                st.write("KhÃ´ng tÃ¬m tháº¥y hÃ nh vi tÆ°Æ¡ng tá»±.")


def display_system_dashboard(qa_system: TrafficLawQASystem):
    """Display comprehensive system dashboard."""
    
    st.header("ðŸ“Š Dashboard Há»‡ thá»‘ng")
    
    # Get comprehensive statistics
    stats = qa_system.get_system_statistics()
    
    # System overview
    st.subheader("ðŸ—ï¸ Tá»•ng quan há»‡ thá»‘ng")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ðŸ“ Tá»•ng Vi pháº¡m",
            stats['knowledge_graph']['node_types'].get('behavior', 0),
            help="Sá»‘ lÆ°á»£ng hÃ nh vi vi pháº¡m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u"
        )
        
    with col2:
        st.metric(
            "ðŸ§  Knowledge Nodes",
            stats['knowledge_graph']['total_nodes'],
            help="Tá»•ng sá»‘ nodes trong knowledge graph"
        )
        
    with col3:
        st.metric(
            "ðŸ”— Relations",
            stats['knowledge_graph']['total_relations'],
            help="Tá»•ng sá»‘ má»‘i quan há»‡ giá»¯a cÃ¡c nodes"
        )
        
    with col4:
        density = stats['knowledge_graph'].get('graph_density', 0)
        st.metric(
            "ðŸ“Š Graph Density",
            f"{density:.3f}",
            help="Máº­t Ä‘á»™ káº¿t ná»‘i cá»§a knowledge graph (0-1)"
        )
    
    # Capabilities overview
    st.subheader("ðŸš€ Kháº£ nÄƒng há»‡ thá»‘ng")
    
    capabilities = stats.get('system_info', {}).get('capabilities', {
        'intent_detection': True,
        'entity_extraction': True, 
        'semantic_search': True,
        'knowledge_reasoning': True,
        'vietnamese_nlp': True
    })
    cap_cols = st.columns(len(capabilities))
    
    for i, (cap_name, enabled) in enumerate(capabilities.items()):
        with cap_cols[i]:
            status_icon = "âœ…" if enabled else "âŒ"
            cap_display = cap_name.replace('_', ' ').title()
            st.metric(cap_display, status_icon)
    
    # Performance metrics
    st.subheader("âš¡ Hiá»‡u suáº¥t")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info(f"""
        **Embedding Model:** {stats['system_info']['embedding_model']}
        
        **Cache Status:** {stats['system_info']['embeddings_cached']} embeddings Ä‘Ã£ cache
        
        **Last Updated:** {stats['system_info']['last_updated'][:19]}
        """)
        
    with col2:
        avg_degree = stats['knowledge_graph'].get('average_degree', 0)
        st.info(f"""
        **Average Node Degree:** {avg_degree:.2f}
        
        **Graph Connectivity:** {'Good' if density > 0.1 else 'Sparse'}
        
        **Data Quality:** {'High' if stats['knowledge_graph']['total_nodes'] > 1000 else 'Medium'}
        """)


def display_benchmark_interface(qa_system: TrafficLawQASystem):
    """Display system benchmarking interface."""
    
    st.header("ðŸ”¬ ÄÃ¡nh giÃ¡ Hiá»‡u suáº¥t Há»‡ thá»‘ng")
    st.markdown("*So sÃ¡nh hiá»‡u quáº£ giá»¯a cÃ¡c phÆ°Æ¡ng phÃ¡p tÃ¬m kiáº¿m vÃ  LLM*")
    
    # Predefined test queries
    test_queries = [
        "Äi xe mÃ¡y vÆ°á»£t Ä‘Ã¨n Ä‘á»",
        "KhÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm",
        "LÃ¡i xe sau khi uá»‘ng rÆ°á»£u",
        "Chá»Ÿ quÃ¡ sá»‘ ngÆ°á»i quy Ä‘á»‹nh",
        "Äá»— xe sai quy Ä‘á»‹nh",
        "KhÃ´ng cÃ³ báº±ng lÃ¡i xe",
        "VÆ°á»£t quÃ¡ tá»‘c Ä‘á»™ cho phÃ©p",
        "Sá»­ dá»¥ng Ä‘iá»‡n thoáº¡i khi lÃ¡i xe",
        "KhÃ´ng tuÃ¢n thá»§ biá»ƒn bÃ¡o giao thÃ´ng",
        "LÃ¡i xe Ã´ tÃ´ khÃ´ng cÃ³ báº£o hiá»ƒm"
    ]
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ðŸ“ Bá»™ test queries")
        
        # Allow custom queries
        custom_queries = st.text_area(
            "ThÃªm cÃ¢u há»i test (má»—i dÃ²ng má»™t cÃ¢u):",
            placeholder="Nháº­p cÃ¡c cÃ¢u há»i Ä‘á»ƒ test, má»—i dÃ²ng má»™t cÃ¢u",
            height=100
        )
        
        if custom_queries.strip():
            additional_queries = [q.strip() for q in custom_queries.split('\n') if q.strip()]
            all_queries = test_queries + additional_queries
        else:
            all_queries = test_queries
            
        st.write(f"**Tá»•ng sá»‘ queries Ä‘á»ƒ test:** {len(all_queries)}")
        
        # Run benchmark
        if st.button("ðŸš€ Cháº¡y Benchmark", type="primary"):
            with st.spinner("Äang cháº¡y benchmark..."):
                benchmark_results = qa_system.benchmark_system(all_queries)
                display_benchmark_results(benchmark_results)
                
    with col2:
        st.subheader("ðŸ“‹ Test Queries máº·c Ä‘á»‹nh")
        for i, query in enumerate(test_queries, 1):
            st.write(f"{i}. {query}")


def display_benchmark_results(results: Dict[str, Any]):
    """Display benchmark results with detailed analysis."""
    
    st.markdown("---")
    st.header("ðŸ“Š Káº¿t quáº£ Benchmark")
    
    # Overall metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ðŸ“ Tá»•ng Queries", results['total_queries'])
    with col2:
        st.metric("âœ… ThÃ nh cÃ´ng", results['successful_answers'])
    with col3:
        success_rate = results['success_rate'] * 100
        st.metric("ðŸŽ¯ Tá»· lá»‡ thÃ nh cÃ´ng", f"{success_rate:.1f}%")
    with col4:
        avg_time = results['average_processing_time']
        st.metric("â±ï¸ Thá»i gian TB", f"{avg_time:.3f}s")
    
    # Confidence distribution
    st.subheader("ðŸ“Š PhÃ¢n bá»‘ Äá»™ tin cáº­y")
    
    conf_dist = results['confidence_distribution']
    if conf_dist:
        col1, col2 = st.columns(2)
        
        with col1:
            # Pie chart for confidence
            fig_conf = px.pie(
                values=list(conf_dist.values()),
                names=list(conf_dist.keys()),
                title="PhÃ¢n bá»‘ Confidence",
                color_discrete_map={
                    'high': '#28a745',
                    'medium': '#ffc107', 
                    'low': '#fd7e14',
                    'none': '#dc3545'
                }
            )
            st.plotly_chart(fig_conf, width="stretch")
            
        with col2:
            # Intent distribution
            intent_dist = results['intent_distribution']
            if intent_dist:
                fig_intent = px.bar(
                    x=list(intent_dist.keys()),
                    y=list(intent_dist.values()),
                    title="PhÃ¢n bá»‘ Intent Types"
                )
                st.plotly_chart(fig_intent, width="stretch")
    
    # Detailed results
    st.subheader("ðŸ“‹ Chi tiáº¿t tá»«ng Query")
    
    query_results = results.get('query_results', [])
    if query_results:
        df_results = pd.DataFrame(query_results)
        
        # Add color coding for confidence
        def color_confidence(val):
            colors = {
                'high': 'background-color: #d4edda',
                'medium': 'background-color: #fff3cd',
                'low': 'background-color: #f8d7da',
                'none': 'background-color: #f8d7da'
            }
            return colors.get(val, '')
        
        if 'confidence' in df_results.columns:
            styled_df = df_results.style.applymap(color_confidence, subset=['confidence'])
            st.dataframe(styled_df, width="stretch")
        else:
            st.dataframe(df_results, width="stretch")
    
    # Performance analysis
    st.subheader("ðŸ“ˆ PhÃ¢n tÃ­ch Hiá»‡u suáº¥t")
    
    if success_rate >= 80:
        st.success("ðŸŽ‰ **Hiá»‡u suáº¥t Xuáº¥t sáº¯c!** Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng ráº¥t tá»‘t vá»›i tá»· lá»‡ thÃ nh cÃ´ng cao.")
    elif success_rate >= 60:
        st.warning("âš ï¸ **Hiá»‡u suáº¥t KhÃ¡ tá»‘t.** CÃ³ thá»ƒ cáº£i thiá»‡n thÃªm Ä‘á»™ chÃ­nh xÃ¡c.")
    else:
        st.error("âŒ **Cáº§n cáº£i thiá»‡n.** Há»‡ thá»‘ng cáº§n Ä‘Æ°á»£c tá»‘i Æ°u hÃ³a thÃªm.")
        
    # Recommendations
    st.subheader("ðŸ’¡ Khuyáº¿n nghá»‹ cáº£i thiá»‡n")
    
    recommendations = []
    
    if results['confidence_distribution'].get('none', 0) > results['total_queries'] * 0.3:
        recommendations.append("ðŸ”§ Cáº§n má»Ÿ rá»™ng cÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘á»ƒ cover nhiá»u trÆ°á»ng há»£p hÆ¡n")
        
    if avg_time > 2.0:
        recommendations.append("âš¡ Cáº§n tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ xá»­ lÃ½ (hiá»‡n táº¡i > 2s)")
        
    if results['confidence_distribution'].get('high', 0) < results['total_queries'] * 0.5:
        recommendations.append("ðŸŽ¯ Cáº§n cáº£i thiá»‡n Ä‘á»™ chÃ­nh xÃ¡c cá»§a semantic search")
        
    if recommendations:
        for rec in recommendations:
            st.write(f"â€¢ {rec}")
    else:
        st.success("âœ… Há»‡ thá»‘ng Ä‘ang hoáº¡t Ä‘á»™ng á»Ÿ má»©c tá»‘i Æ°u!")


if __name__ == "__main__":
    main()


